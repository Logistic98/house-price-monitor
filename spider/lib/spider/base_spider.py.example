#!/usr/bin/env python
# coding=utf-8
# 爬虫基类

import threading
from lib.zone.city import lianjia_cities
from lib.utility.date import *
import random

# 并发的线程数
thread_pool_size = 10

# 防止爬虫被禁，随机延迟设定（True or False）
# 具体时间可以修改random_delay()，由于多线程，建议数值大于10
RANDOM_DELAY = True

# ProxyPool 爬虫代理IP池
# 官方测试地址：http://demo.spiderpy.cn/，建议自建
# 是否开启代理（True or False）
PROXY_SWITCH = True
# 代理服务地址
PROXY_POOL_URL = "http://demo.spiderpy.cn/"
# 是否过滤https（True or False）
PROXY_OPEN_HTTPS = False

# 选择爬取的数据源, LIANJIA_SPIDER或者BEIKE_SPIDER
LIANJIA_SPIDER = "lianjia"
BEIKE_SPIDER = "ke"
SPIDER_NAME = LIANJIA_SPIDER

# MySQL数据库连接信息
HOST = "127.0.0.1"
USER = "test"
PASSWD = "123456"
PORT = 3306
DB = "housedb"
CHARSET = "utf8"


class BaseSpider(object):
    @staticmethod
    def random_delay():
        if RANDOM_DELAY:
            time.sleep(random.randint(0, 10))

    def __init__(self, name):
        self.name = name
        if self.name == LIANJIA_SPIDER:
            self.cities = lianjia_cities
        else:
            self.cities = None
        # 准备日期信息
        self.date_string = get_date_string()
        print('Today date is: %s' % self.date_string)

        self.total_num = 0  # 总的小区个数，用于统计
        print("Target site is {0}.com".format(SPIDER_NAME))
        self.mutex = threading.Lock()  # 创建锁

    def create_prompt_text(self):
        """
        根据已有城市中英文对照表拼接选择提示信息
        :return: 拼接好的字串
        """
        city_info = list()
        count = 0
        for en_name, ch_name in self.cities.items():
            count += 1
            city_info.append(en_name)
            city_info.append(": ")
            city_info.append(ch_name)
            if count % 4 == 0:
                city_info.append("\n")
            else:
                city_info.append(", ")
        return 'Which city do you want to crawl?\n' + ''.join(city_info)

    def get_chinese_city(self, en):
        """
        拼音拼音名转中文城市名
        :param en: 拼音
        :return: 中文
        """
        return self.cities.get(en, None)
